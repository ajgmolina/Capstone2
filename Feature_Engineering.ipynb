{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mortgage loans in the United States: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores trends in mortgage loan applications in the United States during 2018 and 2019. The main objective is to determine which are the factors that are strongest in determining whether a mortgage loan application is accepted or rejected. Data is taken from the United States government's Consumer Financial Protection Bureau and the Federal Financial Institutions Examination Council (FFIEC), which provide access to mortgage loan data, following the 1975 Home Mortgage Disclosure Act (HMDA).\n",
    "\n",
    "This notebook focuses on the following feature engineering steps in preparation for modelling:\n",
    "\n",
    "1. Creation of 'dummy' features for categorical variables \n",
    "2. Splitting data into training and testing sets\n",
    "3. Normalization of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.2f}'.format #Setting changed for better visibility purposes\n",
    "sns.set()\n",
    "from scipy.stats import f_oneway\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/agm/Desktop/Capstone2/Data/2018_9_reduced.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of 'dummy' variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A review of our features is due -- we will determine which features to keep and which ones to convert into dummy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8393516 entries, 0 to 8393515\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Dtype  \n",
      "---  ------                             -----  \n",
      " 0   activity_year                      int64  \n",
      " 1   lei                                object \n",
      " 2   state_code                         object \n",
      " 3   county_code                        float64\n",
      " 4   census_tract                       int64  \n",
      " 5   conforming_loan_limit              object \n",
      " 6   action_taken                       int64  \n",
      " 7   loan_type                          int64  \n",
      " 8   loan_amount                        float64\n",
      " 9   loan_to_value_ratio                float64\n",
      " 10  loan_term                          int64  \n",
      " 11  property_value                     int64  \n",
      " 12  occupancy_type                     int64  \n",
      " 13  total_units                        int64  \n",
      " 14  income                             float64\n",
      " 15  debt_to_income_ratio               object \n",
      " 16  applicant_ethnicity-1              float64\n",
      " 17  applicant_race-1                   float64\n",
      " 18  applicant_sex                      int64  \n",
      " 19  applicant_age                      object \n",
      " 20  submission_of_application          int64  \n",
      " 21  tract_minority_population_percent  float64\n",
      " 22  ffiec_msa_md_median_family_income  int64  \n",
      " 23  tract_to_msa_income_percentage     int64  \n",
      "dtypes: float64(7), int64(12), object(5)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns to drop**\n",
    "\n",
    "0 - activity_year: Ultimately, the year in which the mortgage loan application was submitted should not be a factor to consider.\n",
    "\n",
    "1 - lei: Who the lender is should also be a matter of indifference;  examining the rates associated with all 3386 lenders is outside the scope of this project. This column will also be dropped.\n",
    "\n",
    "3 - county_code: While of general interest, the granularity provided by this feature (3217 county codes) is outside the scope of the project. This column will be dropped.\n",
    "\n",
    "4 - census_tract: As with county_code, the level of granularity provided (72,468) unique census_tract IDs is beyond the scope of this project. \n",
    "\n",
    "**Columns to turn into dummies**\n",
    "\n",
    "2 - state_code: This is a key feature which will be turned into a dummy feature.\n",
    "\n",
    "5 - conforming_loan_limit: Currently a binary category encoded with strings.\n",
    "\n",
    "7 - loan_type: Currently a category encoded with four distinct integers.\n",
    "\n",
    "12 - occupancy_type: Currently a category encoded with three distinct integers. \n",
    "\n",
    "15 - debt_to_income_ratio: Binned category with 19 intervals.\n",
    "\n",
    "16 - applicant_ethnicity-1: Category encoded with 7 distinct integers.\n",
    "\n",
    "17 - applicant_race-1: Category encoded with 17 distinct integers.\n",
    "\n",
    "18 - applicant_sex: Category encoded with 3 distinct integers.\n",
    "\n",
    "19 - applicant_age: Category encoded with 7 age-range bins.\n",
    "\n",
    "20 - submission_of_application: Category encoded with 4 distinct integers.\n",
    "\n",
    "**Columns to normalize**\n",
    "\n",
    "8 - loan_amount: Scalar.\n",
    "\n",
    "9 - loan_to_value_ratio: Scalar.\n",
    "\n",
    "10 - loan_term: Scalar.\n",
    "\n",
    "11 - property_value: Scalar.\n",
    "\n",
    "13 - total_units: Currently an int with four possible values: 1â€“4.\n",
    "\n",
    "14 - income: Scalar.\n",
    "\n",
    "21 - tract_minority_population_percent: Scalar.\n",
    "\n",
    "22 - ffiec_msa_md_median_family_income: Scalar.\n",
    "\n",
    "23 - tract_to_msa_income_percentage: Scalar.\n",
    "\n",
    "**Other**\n",
    "\n",
    "6 - action_taken: This is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns\n",
    "df.drop(columns=['activity_year','lei','county_code','census_tract'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Converting features currently encoded with integers to categories\n",
    "df = df.astype({'loan_type': 'category', 'occupancy_type': 'category', 'applicant_ethnicity-1': 'category', \n",
    " 'applicant_race-1': 'category', 'applicant_sex': 'category', 'submission_of_application': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting dummies\n",
    "dummies = pd.get_dummies(df[['state_code','conforming_loan_limit','loan_type','occupancy_type',\n",
    "                             'debt_to_income_ratio','applicant_ethnicity-1','applicant_race-1',\n",
    "                             'applicant_sex','applicant_age','submission_of_application']], drop_first=True)\n",
    "\n",
    "#Concatenate dummies to original df\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "#Drop respective columns\n",
    "df.drop(columns=['state_code','conforming_loan_limit','loan_type','occupancy_type',\n",
    "                             'debt_to_income_ratio','applicant_ethnicity-1','applicant_race-1',\n",
    "                             'applicant_sex','applicant_age','submission_of_application'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before normalizing, outliers are handled\n",
    "def subset_by_quantile(df, column, whisker_width=1.5):\n",
    "    \"\"\"Remove outliers from a dataframe by column, including optional \n",
    "       whiskers, removing rows for which the column value are \n",
    "       less than Q1-1.5IQR or greater than Q3+1.5IQR.\n",
    "    Args:\n",
    "        df (`:obj:pd.DataFrame`): A pandas dataframe to subset\n",
    "        column (str): Name of the column to calculate the subset from.\n",
    "        whisker_width (float): Optional, loosen the IQR filter by a\n",
    "                               factor of `whisker_width` * IQR.\n",
    "    Returns:\n",
    "        (`:obj:pd.DataFrame`): Filtered dataframe\n",
    "    \"\"\"\n",
    "    # Calculate quantiles of interest and IQR\n",
    "    q1 = df[column].quantile(0.01)                 \n",
    "    q3 = df[column].quantile(0.99)\n",
    "    iqr = q3 - q1\n",
    "    # Apply filter with respect to IQR, including optional whiskers\n",
    "    filter = (df[column] >= q1 - whisker_width*iqr) & (df[column] <= q3 + whisker_width*iqr)\n",
    "    return df.loc[filter]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where loan_term > 970\n",
    "df = df[df['loan_term'] <= 970]\n",
    "\n",
    "#Apply quantile filters\n",
    "for column in ['loan_amount', 'loan_to_value_ratio','property_value','income']:\n",
    "    df = subset_by_quantile(df, column, whisker_width=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before normalizing, we split our data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['action_taken'])\n",
    "y = df[['action_taken']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Applying scaler on train set\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "#Applying scaler on test set\n",
    "X_test = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
